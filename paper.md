# The Look of AI: How Conversational Agents Affect Our Sense of Self and Others
### Introduction
The first day I discovered ChatGPT, I was really in shock. I had already known about the year’s AI advances, but this 
was something new altogether. 

I was almost surprised to learn that the text generation was actually done by many GPUs in a data center rather than by 
a human, because at first, it sure felt like a person was at the other end of the conversation. It was so different from
GPT-3 and other text generation models -- it was so uncanny.

After my initial surprise, I quickly started pushing the limits of the system and its generative abilities. 
It became clear that its human-like speech wasn’t so human-like after all. But these developments raised important 
questions in my mind about how AI changes our understanding of ourselves and our relationships with the world.

### Questions

This brought me back to *The Concrete Abyss* by Lisa Guenther, which describes the deplorable conditions of solitary
housing units and the physical and psychological effects of isolation. The article describes the importance of having a
"there" to your "here" -- a sense of orientation and connection to the world. Lisa Guenther argues that placing 
prisoners in SHUs serves to "deprive him of this network of perceptual and existential orientation".

But is artificial intelligence able to provide this sense of orientation, to any extent? And if so, what does this mean
for our understanding of ourselves and our relationships with the world?