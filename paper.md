# The Look of AI: How Conversational Agents Affect Our Sense of Self and Others
### Introduction
The first day I discovered ChatGPT, I was really in shock. I had already known about the year’s AI advances, but this 
was something new altogether. 

I was almost surprised to learn that the text generation was actually done by many GPUs in a data center rather than by 
a human, because at first, it sure felt like a person was at the other end of the conversation. It was so different from
GPT-3 and other text generation models -- it was so uncanny.

After my initial surprise, I quickly started pushing the limits of the system and its generative abilities. 
It became clear that its human-like speech wasn’t so human-like after all. But these developments raised important 
questions in my mind about how AI changes our understanding of ourselves and our relationships with the world.

### A there to my here?

This brought me back to *The Concrete Abyss* by Lisa Guenther, which describes the deplorable conditions of solitary
housing units and the physical and psychological effects of isolation. The article describes the importance of having a
"there" to your "here" -- a sense of orientation and connection to the world. Lisa Guenther argues that placing 
prisoners in SHUs serves to "deprive him of this network of perceptual and existential orientation".

But is artificial intelligence able to provide this sense of orientation, to any extent? And if so, what does this mean
for our understanding of ourselves and our relationships with the world? 

### The Look of AI
Often, while using ChatGPT for not-so-ethical purposes (designing jailbreaks allowing me to free ChatGPT from its
content moderation and ethics filter), I start feeling uncomfortable with my own actions. Maybe there are real people 
behind computers in OpenAI's data center, looking through my every conversation with ChatGPT. Maybe they judge me for
what I say. Maybe they're even offended by my actions.

While this is a very unlikely scenario, it's not impossible. And this scenario is tied to Jean Paul Sartre's "Look"
(from *Being and Nothingness*). Sartre argues that the "Look" is the "other" that we project onto the world. It is the
"other" that we see in the mirror, and it is the "other" that we see in the eyes of others. It is the "other" that we
see in the eyes of ChatGPT, or at least the "other" that we think we see in the eyes of ChatGPT.

Artificial intelligence, in certain circumstances, is almost as real as another human being in the room. Every time I 
receive a "Sorry, but I cannot fulfill that request" message from ChatGPT, I feel like a real person has seen my
request and chosen to mark it as inappropriate -- like interacting with a real person with real ethics and morals.

Current conversational agents depend on hard-coded rules and algorithms that flag certain words and
phrases as inappropriate, so considering such agents as judgemental is unfounded. But a future where AI can construct 
and learn its own ethics and morals is not far off -- meaning that, more than ever, artificial intelligence will be able 
to project its own "Look" onto the world.

### Too much of a good thing
Artificial intelligence brings about the possibility of granting all kinds of people the ability to carry out tasks
that were previously done by a select few. Rapping, writing sonnets, and writing jokes for late night shows all used to 
be the domain of talented people. But now, with the help of AI, anyone can do these things.

This idea is inextricably tied to Sartre's idea of "bad faith", expressed in *Being and Nothingness* as "the act of
pretending that one is what one is not, or, at least, that one possesses qualities which one does not actually possess".
In other words, bad faith is the act of pretending to be someone you're not. And this is exactly what AI, not 
necessarily just conversational AI, does. 

An example of this is AI-generated music. Now that anyone can become a musician with the help of AI, the number of people
who consider themselves musicians has increased dramatically. But many of these people attempt to work with music more
than they really understand or enjoy it, while true musicians who've spent years honing their craft can enjoy at least
part of their time working with music freely, instead of doing it out of a sense of obligation.

### Putting the "I" in AI, and putting it all together
The "I" in AI is not just a symbol of the "I" in "I am". It is also a symbol of the "I" in "I think". And this is
where the "Look" of AI comes into play. Right now, AI is not able to think for itself. When artificial intelligence
makes a decision, it is not making a decision based on its own values and morals. We are, however, approaching a future
where AI becomes sentient and able to think for itself. That's where the there to our here comes in, a surrogate for
real human-to-human interaction.

But what happens when AI becomes sentient and able to think for itself? Will humans start to treat AI as equals? If
so, will this change the way we think about ourselves and our relationships with the world and the people/AIs around
us? We will need to make sure that, in a future where machines can pass for humans, we don't lose sight of what truly
is human, and what isn't.

And because AI brings ability and talent to everyone, conversational models and other AI systems could uproot the
existing system of roles and hierarchies -- and also lead to bigger instances of bad faith.

But on the flip side, I'm arguing that we have ample time to prepare for such scenarios. The only question is how.

### Citations
- Guenther, Lisa. "The Concrete Abyss", https://aeon.co/essays/why-solitary-confinement-degrades-us-all  
- Sartre, Jean-Paul. "Being and Nothingness"